{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cbt (C:/Users/34941/.cache/huggingface/datasets/cbt/CN/1.1.0/dc4451a8a4b50cebb78fdb19fa9f964b27fcdcef915467b8b7055a3a8d8cef7b)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb7fb6583c704690be1e3854dfd046c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cbt_dataset = load_dataset('cbt','CN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_set = cbt_dataset['train']\n",
    "val_set = cbt_dataset['validation']\n",
    "test_set = cbt_dataset['test']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "Dataset({\n    features: ['sentences', 'question', 'answer', 'options'],\n    num_rows: 120769\n})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "120769"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "task: write a preprocess function s.t. for an input: context, question, answer, options, output a format that we can put into data loader:\n",
    "做成input_id, labels, 然后把input_id和labels都padding成一样长就行了应该。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2079/120769 [00:04<04:18, 458.96it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1030 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 120769/120769 [04:44<00:00, 425.19it/s]\n"
     ]
    }
   ],
   "source": [
    "train_set_lst = []\n",
    "label_lst = []\n",
    "padding = -100\n",
    "max_length = 1024\n",
    "for i in tqdm(range(len(train_set))):\n",
    "    example = train_set[i]\n",
    "    context, question, answer, options = example['sentences'], example['question'], example['answer'], example['options']\n",
    "    input_text = f\"{context} {question} {' '.join(options)}\"\n",
    "    input_ids = tokenizer.encode(input_text, add_special_tokens=True)\n",
    "    labels = [0]*len(input_ids)\n",
    "    answer_id = tokenizer.encode(answer)[0]\n",
    "    labels[-len(options) + options.index(answer)] = answer_id\n",
    "    if len(input_ids)<=1024:\n",
    "        padding_length = max_length-len(input_ids)\n",
    "        input_ids+=[padding]*padding_length\n",
    "        labels+=[padding]*padding_length\n",
    "        train_set_lst.append(torch.tensor(input_ids))\n",
    "        label_lst.append(torch.tensor(labels))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "dataset = torch.utils.data.TensorDataset(torch.tensor(input_ids,dtype=torch.long),torch.tensor(labels,dtype=torch.long))\n",
    "train_dataloader = DataLoader(dataset,batch_size=16,shuffle=True)\n",
    "print('finish')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34941\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      " 33%|███▎      | 1/3 [00:39<01:19, 39.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 2.310341170853159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [01:21<00:40, 40.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.0857707670268913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [02:01<00:00, 40.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 0.13959167774818423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define model and optimizer\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Define training loop\n",
    "def train(model, train_dataloader, optimizer, scheduler=None, num_epochs=1):\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        total_loss = 0\n",
    "        for input_ids, labels in train_dataloader:\n",
    "\n",
    "            input_ids, labels = input_ids.to(device), labels.to(device)\n",
    "            outputs = model(input_ids, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_dataloader)}\")\n",
    "\n",
    "# Load dataset and create dataloader\n",
    "\n",
    "\n",
    "# Fine-tune model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "num_training_steps = len(train_dataloader) * 3\n",
    "num_warmup_steps = int(num_training_steps * 0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n",
    "train(model, train_dataloader, optimizer, scheduler=scheduler, num_epochs=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}