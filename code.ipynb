{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, GPT2Model, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cbt_dataset = load_dataset('cbt','CN')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set = cbt_dataset['train']\n",
    "val_set = cbt_dataset['validation']\n",
    "test_set = cbt_dataset['test']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = GPT2Model.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "example = train_set[1]\n",
    "context, question, answer, options = example['sentences'], example['question'], example['answer'], example['options']\n",
    "input_text = f\"{context} {question} {' '.join(options)}\"\n",
    "tokenizer(input_text, add_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_ids,attention_mask = tokenizer(input_text, add_special_tokens=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_ids"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "task: write a preprocess function s.t. for an input: context, question, answer, options, output a format that we can put into data loader:\n",
    "做成input_id, labels, 然后把input_id和labels都padding成一样长就行了应该。"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set_lst = []\n",
    "label_lst = []\n",
    "attn_lst = []\n",
    "token_type_id_lst = []\n",
    "padding = 50256\n",
    "max_length = 1024\n",
    "for i in tqdm(range(int(len(train_set)/500))):\n",
    "    example = train_set[i]\n",
    "    context, question, answer, options = example['sentences'], example['question'], example['answer'], example['options']\n",
    "    option = [example['question'].replace('XXXXX', option) for option in example['options']]\n",
    "    input_text = [''.join(example[\"sentences\"]) + opt for opt in option]\n",
    "    labels = [1 if option == answer else 0 for option in options]\n",
    "\n",
    "    for i in range(len(input_text)):\n",
    "        input = input_text[i]\n",
    "        label = labels[i]\n",
    "        input_ids,attention_mask = tokenizer(input, add_special_tokens=True)['input_ids'],tokenizer(input, add_special_tokens=True)['attention_mask']\n",
    "        context_length = len(input_ids)-len(question)\n",
    "        question_length = len(question)\n",
    "        token_type_id = [0] * context_length + [1] * question_length\n",
    "        if len(input_ids)<=max_length:\n",
    "            padding_length = max_length-len(input_ids)\n",
    "            input_ids+=[padding]*padding_length\n",
    "            attention_mask+=[padding]*padding_length\n",
    "            token_type_id+=[padding]*padding_length\n",
    "            train_set_lst.append(input_ids)\n",
    "            attn_lst.append(attention_mask)\n",
    "            token_type_id_lst.append(token_type_id)\n",
    "            label_lst.append(label)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(torch.tensor(train_set_lst),torch.tensor(attn_lst),torch.tensor(token_type_id_lst),torch.tensor(label_lst))\n",
    "train_dataloader = DataLoader(dataset,batch_size=1,shuffle=True)\n",
    "print('finish')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class GPT2ForMultipleChoice(nn.Module):\n",
    "    def __init__(self, gpt2_model):\n",
    "        super().__init__()\n",
    "        self.gpt2 = gpt2_model\n",
    "        self.classifier = nn.Linear(self.gpt2.config.n_embd, 1)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids):\n",
    "        #input_shape = input_ids.size()\n",
    "        #input_ids = input_ids.view(-1, input_shape[-1])\n",
    "        #attention_mask = attention_mask.view(-1, input_shape[-1]) if attention_mask is not None else None\n",
    "        #token_type_ids = token_type_ids.view(-1, input_shape[-1]) if token_type_ids is not None else None\n",
    "\n",
    "        outputs = self.gpt2(input_ids=input_ids,  token_type_ids=token_type_ids)\n",
    "        outputs = outputs.last_hidden_state\n",
    "        pooled_output = outputs[0]\n",
    "        logits = self.classifier(pooled_output)\n",
    "    \n",
    "        return logits"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = GPT2Model.from_pretrained('gpt2').to(device)\n",
    "input_ids = torch.tensor([train_set_lst[0]]).view(-1,1).to(device)\n",
    "print(input_ids.shape)\n",
    "attention_mask = torch.tensor([attn_lst[0]]).to(device)\n",
    "token_type_id = torch.tensor([token_type_id_lst[0]]).view(-1,1).to(device)\n",
    "label = torch.tensor([label_lst[0]]).to(device)\n",
    "gpt_output = model(input_ids = input_ids,  token_type_ids = token_type_id)\n",
    "gpt_output.last_hidden_state"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define model and optimizer\n",
    "#model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Define training loop\n",
    "def train(model, train_dataloader, optimizer, scheduler=None, num_epochs=1):\n",
    "    model.train()\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        total_loss = 0\n",
    "        for batch in train_dataloader:\n",
    "\n",
    "            input_ids, attention_mask,token_type_ids, labels = batch[0].to(device),batch[1].to(device), batch[2].to(device),batch[3].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(input_ids = input_ids.view(-1,1), token_type_ids = token_type_ids.view(-1,1))\n",
    "            criterion = torch.nn.BCEWithLogitsLoss().to(device)\n",
    "            loss = criterion(logits,labels.view(-1,1).float())\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_dataloader)}\")\n",
    "\n",
    "# Load dataset and create dataloader\n",
    "\n",
    "model2 = GPT2ForMultipleChoice(model)\n",
    "# Fine-tune model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model2.to(device)\n",
    "num_training_steps = len(train_dataloader) * 3\n",
    "num_warmup_steps = int(num_training_steps * 0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)\n",
    "train(model2, train_dataloader, optimizer, scheduler=scheduler, num_epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logit = torch.tensor([[0.5585]])\n",
    "label = torch.tensor([1]).view(-1,1).float()\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "criterion(logit,label)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logit.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: Quadro RTX 8000\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, using CPU instead.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "一个问题变成10个sample，每个变成 binary classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}